{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guerinjeanmarc/FraudWorkshop/blob/main/P2p_Fraud_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7IAIHDeEL1fA"
      },
      "source": [
        "# Exploring Fraud Detection With Neo4j & Graph Data Science\n",
        "\n",
        "This analysis uses [Neo4j and Graph Data Science (GDS)](https://neo4j.com/docs/graph-data-science/current/) to explore an anonymized data sample from a Peer-to-Peer (P2P) payment platform.  The notebook is split up into the following sections to cover various stages of the graph data science workflow:\n",
        "\n",
        "- Notebook Setup\n",
        "- Part 1: Exploring Connected Fraud Data\n",
        "- Part 2: Resolving Fraud Communities using Entity Resolution and Community Detection\n",
        "- Part 3: Recommending Suspicious Accounts With Centrality & Node Similarity\n",
        "- Part 4: Predicting Fraud Risk Accounts with Machine Learning\n",
        "\n",
        "Original Source: https://github.com/neo4j-product-examples/demo-fraud-detection-with-p2p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "fRtB5_lVL1fD"
      },
      "source": [
        "## Notebook Setup <a name=\"p0\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTvuy5y8L1fD"
      },
      "outputs": [],
      "source": [
        "# additional dependencies \n",
        "# !pip install graphdatascience \n",
        "# !pip install scikit-learn==1.1.1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kHzpKazSL1fE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os \n",
        "pd.set_option('display.width', 0)\n",
        "pd.set_option('display.max_colwidth', 500)\n",
        "pd.set_option('display.max_rows', 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ctRnYxCgL1fF"
      },
      "source": [
        "### Neo4j Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "BuhpM3wVL1fF"
      },
      "outputs": [],
      "source": [
        "# HOST = 'neo4j://localhost'\n",
        "# USERNAME = 'neo4j'\n",
        "# PASSWORD = 'password'\n",
        "# DATABASE = 'p2p'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cB8DfmlL1fF"
      },
      "outputs": [],
      "source": [
        "# replace XXX with your user number and enter your password\n",
        "HOST = 'neo4j+s://neo4j-sky.graphdatabase.ninja:443'\n",
        "USERNAME = 'attendeeXX'\n",
        "PASSWORD = 'your_password_here'\n",
        "DATABASE = 'p2pXX'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tLSOd-4L1fG"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv('credentials.env')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "tags": [],
        "id": "GLuwD9XuL1fG"
      },
      "source": [
        "### Connect to Graph Data Science"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tuBONip6L1fH"
      },
      "outputs": [],
      "source": [
        "from graphdatascience import GraphDataScience\n",
        "\n",
        "# Use Neo4j URI and credentials according to your setup\n",
        "gds = GraphDataScience(HOST, auth=(USERNAME, PASSWORD), aura_ds=False)\n",
        "gds.set_database(DATABASE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JvYAo1W3L1fH"
      },
      "source": [
        "## Part 1: Exploring Connected Fraud Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access to Neo4j Browser is here https://neo4j-sky.graphdatabase.ninja/browser/\n",
        "\n",
        "Access to Bloom is here https://neo4j-sky.graphdatabase.ninja/bloom"
      ],
      "metadata": {
        "id": "1ZZFmhNvQpAN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5xPLot2L1fH"
      },
      "source": [
        "### Dataset Introduction\n",
        "***\n",
        "<span style=\"color:green\"> _Below is a query you can use to visualize the graph schema in Neo4j Browser_ </span> \n",
        "\n",
        "`CALL db.schema.visualization`\n",
        "***\n",
        "We will be using an anonymized sample of user accounts and transactions from a real-world Peer-to-Peer (P2P) platform. Prior to ingesting the data into graph, the original identification numbers were removed and categorical values were masked. Each user account has a unique 128-bit identifier, while the other nodes, representing unique credit cards, devices, and ip addresses have been assigned random UUIDs. These identifiers are stored as the guid property in the graph schema.\n",
        "\n",
        "Each user node has a property to indicate money transfer fraud (named `MoneyTransferFraud`) that is 1 for known fraud and 0 otherwise. This indicator is determined by a combination of credit card chargeback events and manual review. A chargeback is an action taken by a bank to reverse electronic payments. It involves reversing a payment and triggering a dispute resolution process, often for billing errors and unauthorized credit use. In short, a user must have at least one chargeback to be considered fraudulent. Only a small proportion of the user accounts, roughly 0.7 %, are flagged for fraud.\n",
        "\n",
        "Below is a breakdown of high-level counts by labels and relationships as well as the flagged accounts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AEggIDzGL1fI"
      },
      "outputs": [],
      "source": [
        "# total node counts\n",
        "gds.run_cypher('''\n",
        "    CALL apoc.meta.stats()\n",
        "    YIELD labels\n",
        "    UNWIND keys(labels) AS nodeLabel\n",
        "    RETURN nodeLabel, labels[nodeLabel] AS nodeCount\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eI6Z90C1L1fI"
      },
      "outputs": [],
      "source": [
        "# total relationship counts\n",
        "gds.run_cypher('''\n",
        "    CALL apoc.meta.stats()\n",
        "    YIELD relTypesCount\n",
        "    UNWIND keys(relTypesCount) AS relationshipType\n",
        "    RETURN relationshipType, relTypesCount[relationshipType] AS relationshipCount\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5y1VaQm-L1fI"
      },
      "outputs": [],
      "source": [
        "#fraud money transfer flags\n",
        "gds.run_cypher('MATCH(u:User) RETURN u.fraudMoneyTransfer AS fraudMoneyTransfer, count(u) AS cnt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsNgTqwEL1fJ"
      },
      "source": [
        "### A Closer Look at Cards and Devices\n",
        "\n",
        "As a first step, we break out the ratio of fraud vs non-fraud users connected to credit cards and devices below. We find that very few cards or devices are centered well around flagged accounts. This is a bit surprising. If a card or device is used by a flagged account, we would expect the other accounts that use the card/device to also be mostly flagged for fraud as well. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nf0OlxydL1fJ"
      },
      "outputs": [],
      "source": [
        "# Setting a label for flagged users will enable faster lookups in cypher and faster gds projections\n",
        "gds.run_cypher('MATCH(u:User) WHERE u.fraudMoneyTransfer=1 SET u:FlaggedUser RETURN count(u)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRcJeWs7L1fJ"
      },
      "source": [
        "To evaluate the connectivity of cards and devices to multiple Users and FlaggedUsers, we project the relevant nodes and relationships into an in-memory graph, and then use [Degree Centrality](https://neo4j.com/docs/graph-data-science/2.1/algorithms/degree-centrality/) with the GDS library to count the incoming and outgoing relationships. `writeNodeProperties` ([Node Operations Docs](https://neo4j.com/docs/graph-data-science/current/graph-catalog-node-ops/)) captures the results and writes them back to the database as properties on the specified node types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxsIO5skL1fJ"
      },
      "outputs": [],
      "source": [
        "# GDS degree centrality to count the number of Users connected to each identifier type - Card, Device, IP\n",
        "g, _  = gds.graph.project('id-projection', ['User', 'Card', 'Device', 'IP'],{\n",
        "        'HAS_CC': {'orientation': 'REVERSE'},\n",
        "        'HAS_IP': {'orientation': 'REVERSE'},\n",
        "        'USED': {'orientation': 'REVERSE'}\n",
        "    })\n",
        "gds.degree.mutate(g, mutateProperty='degree')\n",
        "gds.graph.writeNodeProperties(g, ['degree'], ['Card', 'Device', 'IP'])\n",
        "g.drop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnvtAafAL1fJ"
      },
      "outputs": [],
      "source": [
        "# GDS degree centrality to count the number of Flagged Users connected to each identifier type - Card, Device, IP\n",
        "g, _  = gds.graph.project('id-projection', ['FlaggedUser', 'Card', 'Device', 'IP'],{\n",
        "        'HAS_CC': {'orientation': 'REVERSE'},\n",
        "        'HAS_IP': {'orientation': 'REVERSE'},\n",
        "        'USED': {'orientation': 'REVERSE'}\n",
        "    })\n",
        "gds.degree.mutate(g, mutateProperty='flaggedDegree')\n",
        "gds.graph.writeNodeProperties(g, ['flaggedDegree'], ['Card', 'Device', 'IP'])\n",
        "g.drop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RHmN-9DrL1fK"
      },
      "outputs": [],
      "source": [
        "# Calculate the ratio of flagged users to total users\n",
        "gds.run_cypher('''\n",
        "    MATCH(n) WHERE n:Card OR n:Device OR n:IP\n",
        "    SET n.flaggedRatio = toFloat(n.flaggedDegree)/toFloat(n.degree)\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjxrd8xUL1fK"
      },
      "source": [
        "*** \n",
        "<span style=\"color:green\"> _Run these queries to view some of the results in Neo4j Browser_ </span> \n",
        "\n",
        "\n",
        "Review the results\n",
        "\n",
        "```cypher\n",
        "MATCH (n:Card) \n",
        "RETURN n.guid AS cardId, n.degree AS degree, n.flaggedDegree AS flaggedDegree, n.flaggedRatio AS flaggedUserRatio\n",
        "ORDER BY degree DESC LIMIT 10\n",
        "```\n",
        "\n",
        "View use of a single card by flagged and un-flagged users\n",
        "\n",
        "```cypher \n",
        "MATCH p=(n:Card {guid: \"4f694da1-efe6-4087-bfd4-4c28b642b45f\"})-[]-(u:User)\n",
        "RETURN p\n",
        "```\n",
        "***\n",
        "\n",
        "<br>\n",
        "\n",
        "Below we can calculate the ratio of flagged to unflagged users. This is where we find that very few cards or devices are centered well around flagged accounts (for example only 31 Cards are _only_ used by FlaggedUsers) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Q7dQROiML1fK"
      },
      "outputs": [],
      "source": [
        "print('Flagged User Ratio for Card Count')\n",
        "gds.run_cypher('''\n",
        "    MATCH(n:Card) WHERE n.degree > 1\n",
        "    WITH toFloat(count(n)) AS total\n",
        "    MATCH(n:Card) WHERE n.degree > 1\n",
        "    WITH n, total, CASE\n",
        "        WHEN n.flaggedRatio=0 THEN '0'\n",
        "        WHEN n.flaggedRatio=1  THEN '1'\n",
        "        ELSE 'Between 0-1' END AS flaggedUserRatio\n",
        "    RETURN flaggedUserRatio, count(n) AS count, round(toFloat(count(n))/total,3) AS percentCount, total as totalUsers\n",
        "    ORDER BY flaggedUserRatio\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PptaC0vBL1fK"
      },
      "outputs": [],
      "source": [
        "print('Flagged User Ratio for Device Count')\n",
        "gds.run_cypher('''\n",
        "    MATCH(n:Device) WHERE n.degree > 1\n",
        "    WITH toFloat(count(n)) AS total\n",
        "    MATCH(n:Device) WHERE n.degree > 1\n",
        "    WITH n, total, CASE\n",
        "        WHEN n.flaggedRatio=0 THEN '0'\n",
        "        WHEN n.flaggedRatio=1  THEN '1'\n",
        "        ELSE 'Between 0-1' END AS flaggedUserRatio \n",
        "    RETURN flaggedUserRatio, count(n) as count, round(toFloat(count(n))/total,3) AS percentCount, total as totalUsers \n",
        "    ORDER BY flaggedUserRatio\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "wYRp1X7IL1fK"
      },
      "source": [
        "## Part 2: Resolving Fraud Communities using Entity Resolution and Community Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "tags": [],
        "id": "6YwFOlIUL1fL"
      },
      "source": [
        "#### Exploring Potential Fraud Patterns with Community Detection\n",
        "\n",
        "Given the mixed usage of devices by flagged and unflagged users we discovered above, we suspect fraud activity is not completely labeled. This may be because of the limited chargeback logic used to flag fraud. At the same time we do not want to simply label every user that shares a card or device with another flagged account, since it is possible that a benign user's device and or card was used fraudulently by another. Since fraudsters are actively avoiding being identified, actors committing fraud are often not just represented by a single user account, but rather by multiple accounts and identifiers which, hopefully for us, share some connections and similarities.\n",
        "\n",
        "<br>\n",
        "\n",
        "With graphs, we can attempt to roughly identify these fragmented identities with **Community Detection**, a large set of methods that attempt to partition graphs into well connected groups a.k.a. Communities, where the connectivity in the communities is significantly higher than outside the community."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIGn6zt2L1fL"
      },
      "source": [
        "<br>\n",
        "In fraud detection we often need to identify communities that reflect underlying groups of individuals. Due to expectations of auditability, it is important the process be explainable. In this section we will follow a scalable and explainable process to identify additional fraud risk users. \n",
        "\n",
        "* Define Entity Resolution (ER) rules to link Users who may be the same individual with derived relationships\n",
        "* Use the determanistic and explainable algorithm [Weakly Connected Components (WCC)](https://neo4j.com/docs/graph-data-science/current/algorithms/wcc/) to resolve the communities based on our derived relationships \n",
        "* Label all users in communities that include flagged accounts as fraud risks.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zQLRF4y5L1fL"
      },
      "source": [
        "### Entity Resolution Business Rules\n",
        "\n",
        "We will now use Entity Resolution (ER) to resolve groups of individuals behind sets of user accounts. For this analysis, we will use some pretty straightforward ER business logic. If either of the two below conditions are true, we will resolve two user accounts by linking them together with a new relationship type.\n",
        "\n",
        "1. One user sent money to another user that shares the same credit card\n",
        "2. Two users share a card or device connected to less than or equal to 10 total accounts, and those two users also share at least two other identifiers of type credit card, device, or IP address\n",
        "\n",
        "You could switch out or add different rules to the above, these are just examples. In a real-world scenario these business rules would pass by SMEs and possibly be backed by further supervised machine learning on manually labeled data. More advanced techniques for this type of ER are possible in graph and we describe them in [this whitepaper](https://neo4j.com/whitepapers/graph-data-science-use-cases-entity-resolution/) and [this blog](https://neo4j.com/developer-blog/exploring-supervised-entity-resolution-in-neo4j/).\n",
        "\n",
        "For a P2P dataset, we do not necessarily want to label all senders/receivers of flagged user transactions as fraudulent since some fraud schemes involve transactions with victims. Furthermore, additional identifiers such as IP may be inexact and cards + devices can be fraudulently controlled/used without the owners permission. Hence we use somewhat stringent rules that align with the patterns noted in Part 1. We can apply relationships to reflect these business rules using cypher:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eA3Udr3cL1fL"
      },
      "outputs": [],
      "source": [
        "# P2P with shared card rule\n",
        "gds.run_cypher('''\n",
        "    MATCH (u1:User)-[r:P2P]->(u2)\n",
        "    WITH u1, u2, count(r) AS cnt\n",
        "    MATCH (u1)-[:HAS_CC]->(n)<-[:HAS_CC]-(u2)\n",
        "    WITH u1, u2, count(DISTINCT n) AS cnt\n",
        "    MERGE(u1)-[s:P2P_WITH_SHARED_CARD]->(u2)\n",
        "    RETURN count(DISTINCT s) AS cnt\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5HcmZw_YL1fL"
      },
      "outputs": [],
      "source": [
        "# Shared ids rule\n",
        "gds.run_cypher('''\n",
        "    MATCH (u1:User)-[:HAS_CC|USED]->(n)<-[:HAS_CC|USED]-(u2)\n",
        "    WHERE n.degree <= 10 AND id(u1) < id(u2)\n",
        "    WITH u1, u2, count(DISTINCT n) as cnt\n",
        "    MATCH (u1)-[:HAS_CC|USED|HAS_IP]->(m)<-[:HAS_CC|USED|HAS_IP]-(u2)\n",
        "    WITH u1, u2, count(DISTINCT m) as cnt\n",
        "    WHERE cnt > 2\n",
        "    MERGE(u1)-[s:SHARED_IDS]->(u2)\n",
        "    RETURN count(DISTINCT s)\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hqw6z4fTL1fL"
      },
      "source": [
        "### Using Weakly Connected Components (WCC) to Resolve Communities\n",
        "\n",
        "[Weakly Connected Components (WCC)](https://neo4j.com/docs/graph-data-science/current/algorithms/wcc/) is a practical and highly scalable community detection algorithm. It is also deterministic and very explainable. It defines a community simply as a set of nodes connected by a subset of relationship types in the graph. This makes WCC a good choice for formal community assignment in production fraud detection settings.\n",
        "\n",
        "Below we run WCC on a graph projection consisting of Users and the ER relationships created above, then write out the resulting community IDs as wccId\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gKvjrV0-L1fM"
      },
      "outputs": [],
      "source": [
        "g, _ = gds.graph.project('comm-projection', ['User'], {\n",
        "    'SHARED_IDS': {'orientation': 'UNDIRECTED'},\n",
        "    'P2P_WITH_SHARED_CARD': {'orientation': 'UNDIRECTED'}\n",
        "})\n",
        "\n",
        "df = gds.wcc.write(g, writeProperty='wccId')\n",
        "g.drop()\n",
        "# df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6NDt8Fr_L1fM"
      },
      "source": [
        "### Labeling Fraud Risk User Accounts\n",
        "\n",
        "As these communities are meant to label underlying groups of individuals, if even one flagged account is in the community, we will label all user accounts in the group as fraud risks:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "v946MIMjL1fM"
      },
      "outputs": [],
      "source": [
        "gds.run_cypher('''\n",
        "    MATCH (f:FlaggedUser)\n",
        "    WITH collect(DISTINCT f.wccId) AS flaggedCommunities\n",
        "    MATCH(u:User) WHERE u.wccId IN flaggedCommunities\n",
        "    SET u:FraudRiskUser\n",
        "    SET u.fraudRisk=1\n",
        "    RETURN count(u)\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "l40Hl5IhL1fM"
      },
      "outputs": [],
      "source": [
        "gds.run_cypher('''\n",
        "    MATCH (u:User) WHERE NOT u:FraudRiskUser\n",
        "    SET u.fraudRisk=0\n",
        "    RETURN count(u)\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sit034kzL1fM"
      },
      "source": [
        "### WCC Community Statistics\n",
        "\n",
        "The breakdown of communities by size is listed below. The majority are single user communities. Only a small portion have multiple users and of those, community sizes are mostly 2 and 3. Larger communities are rare. However, if we look at the fraudUser accounts we will see that the majority reside in multi-user communities. The 118 fraud accounts in single user communities are flagged users (via original chargeback logic) that have yet to be resolved to a community."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "N6TiQuwuL1fM"
      },
      "outputs": [],
      "source": [
        "gds.run_cypher( '''\n",
        "    MATCH (u:User)\n",
        "    WITH u.wccId AS community, count(u) AS cSize, sum(u.fraudRisk) AS cFraudSize\n",
        "    WITH community, cSize, cFraudSize,\n",
        "    CASE\n",
        "        WHEN cSize=1 THEN ' 1'\n",
        "        WHEN cSize=2 THEN ' 2'\n",
        "        WHEN cSize=3 THEN ' 3'\n",
        "        WHEN cSize>3 AND cSize<=10 THEN ' 4-10'\n",
        "        WHEN cSize>10 AND cSize<=50 THEN '11-50'\n",
        "        WHEN cSize>50 THEN '>50' END AS componentSize\n",
        "    RETURN componentSize, \n",
        "        count(*) AS numberOfComponents, \n",
        "        sum(cSize) AS totalUserCount, \n",
        "        sum(cFraudSize) AS fraudUserCount \n",
        "    ORDER BY componentSize\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "w39A0x4GL1fM"
      },
      "source": [
        "***\n",
        "<span style=\"color:green\"> To view individual communities in Neo4j Browser </span>\n",
        "\n",
        "First, get a list of \"interesting\" communities that contain a mix of labeled fraud Users (`fraudMoneyTransfer=1`), and fraud risk Users inferred from the WCC community detection labeling. \n",
        "```cypher\n",
        "MATCH (u:User)\n",
        "WITH u.wccId AS community, count(u) AS cSize, sum(u.fraudMoneyTransfer) as cLabeledFraud\n",
        "WHERE (cSize<>cLabeledFraud) AND cLabeledFraud>0\n",
        "RETURN community as communityId, cSize as communitySize, cLabeledFraud as labeledFraudUsers ORDER BY communitySize DESC\n",
        "```\n",
        "\n",
        "Next, choose a communityId and set it as a parameter - for example community 2153\n",
        "```cypher \n",
        ":param id=>2153;\n",
        "```\n",
        "\n",
        "Finally, copy-paste the following query into your browser cell \n",
        "<span style=\"color:red\"> ** note, delete the backslash before the parameter id! This is just a markdown formatting workaround.</span>\n",
        "```cypher\n",
        "MATCH(u1:User{wccId: \\$id})-[r1:HAS_CC|USED]->(n)<-[r2:HAS_CC|USED]-(u2:User{wccId: $id})\n",
        "WITH *\n",
        "OPTIONAL MATCH (u1)-[r3:P2P]-(u2)\n",
        "RETURN *\n",
        "```\n",
        "\n",
        "\n",
        "Overall, you will notice a high degree of overlapping connectivity of identifiers and P2P transactions between users, which we should expect given our ER rules.\n",
        "*** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "9Y882sWsL1fN"
      },
      "source": [
        "### Outcomes of Fraud Risk Labeling\n",
        "Fraud Risk labeling helped identify an additional 211 new fraud risk user accounts, nearly doubling the number of known fraud users (87.5% increase). We also see that 65% of the money going to/from previously flagged accounts and other users can be attributed to the newly identified risk accounts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "clD3HJS5L1fN"
      },
      "outputs": [],
      "source": [
        "gds.run_cypher('''\n",
        "   MATCH (:FlaggedUser)-[r:P2P]-(u)  WHERE NOT u:FlaggedUser\n",
        "   WITH toFloat(sum(r.totalAmount)) AS p2pTotal\n",
        "   MATCH (u:FraudRiskUser)-[r:P2P]-(:FlaggedUser) WHERE NOT u:FlaggedUser\n",
        "   WITH p2pTotal,  toFloat(sum(r.totalAmount)) AS fraudRiskP2pTotal\n",
        "   RETURN round((fraudRiskP2pTotal)/p2pTotal,3) AS p\n",
        "''').p[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "C1MbXyDXL1fN"
      },
      "source": [
        "Additionally, while the newly identified 211 accounts represents less than 1% of total users in the sample, 12.7% of the total P2P amount in the sample involved the newly identified accounts as senders or receivers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tG5cckYlL1fN"
      },
      "outputs": [],
      "source": [
        "gds.run_cypher('''\n",
        "   MATCH (:User)-[r:P2P]->()\n",
        "   WITH toFloat(sum(r.totalAmount)) AS p2pTotal\n",
        "   MATCH (u:FraudRiskUser)-[r:P2P]-() WHERE NOT u:FlaggedUser\n",
        "   WITH p2pTotal, toFloat(sum(r.totalAmount)) AS fraudRiskP2pTotal\n",
        "   RETURN round((fraudRiskP2pTotal)/p2pTotal,3) AS p\n",
        "''').p[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "E3reTRYUL1fN"
      },
      "source": [
        "Finally, we can see an improvement in card and device discrimination with many more cards and devices being used by fraud risk accounts exclusively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rF8-6FpL1fN"
      },
      "outputs": [],
      "source": [
        "# GDS degree centrality to count the number of FraudRisk Users connected to each identifier type - Card, Device, IP\n",
        "g, _  = gds.graph.project('id-projection', ['FraudRiskUser', 'Card', 'Device', 'IP'],{\n",
        "        'HAS_CC': {'orientation': 'REVERSE'},\n",
        "        'HAS_IP': {'orientation': 'REVERSE'},\n",
        "        'USED': {'orientation': 'REVERSE'}\n",
        "    })\n",
        "gds.degree.mutate(g, mutateProperty='fraudRiskDegree')\n",
        "gds.graph.writeNodeProperties(g, ['fraudRiskDegree'], ['Card', 'Device', 'IP'])\n",
        "g.drop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "267EWE-4L1fN"
      },
      "outputs": [],
      "source": [
        "gds.run_cypher('''\n",
        "    MATCH(n) WHERE n:Card OR n:Device OR n:IP\n",
        "    SET n.fraudRiskRatio = toFloat(n.fraudRiskDegree)/toFloat(n.degree)\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-HjTcovL1fO"
      },
      "source": [
        "Below we re-calculate the ratio of flagged to unflagged users. We now see an increase in cards/devices used only by FraudRiskUsers (from 31 to 351 for Cards)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "X-0e4vAdL1fO"
      },
      "outputs": [],
      "source": [
        "gds.run_cypher('''\n",
        "    MATCH(n:Card) WHERE n.degree > 1\n",
        "    WITH toFloat(count(n)) AS total\n",
        "    MATCH(n:Card) WHERE n.degree > 1\n",
        "    WITH n, total, CASE\n",
        "        WHEN n.fraudRiskRatio=0 THEN '0'\n",
        "        WHEN n.fraudRiskRatio=1  THEN '1'\n",
        "        ELSE 'Between 0-1' END AS fraudRiskRatio\n",
        "    WITH fraudRiskRatio, n, total\n",
        "    RETURN fraudRiskRatio, count(n) AS count, round(toFloat(count(n))/total,3) AS percentCount, total as totalUsers\n",
        "    ORDER BY fraudRiskRatio\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "o6_ITFW_L1fO"
      },
      "outputs": [],
      "source": [
        "gds.run_cypher('''\n",
        "    MATCH(n:Device) WHERE n.degree > 1\n",
        "    WITH toFloat(count(n)) AS total\n",
        "    MATCH(n:Device) WHERE n.degree > 1\n",
        "    WITH n, total, CASE\n",
        "        WHEN n.fraudRiskRatio=0 THEN '0'\n",
        "        WHEN n.fraudRiskRatio=1  THEN '1'\n",
        "        ELSE 'Between 0-1' END AS fraudRiskRatio\n",
        "    RETURN fraudRiskRatio, count(n) AS count, round(toFloat(count(n))/total,3) AS percentCount, total as totalUsers \n",
        "    ORDER BY fraudRiskRatio\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "wWoBP3pXL1fO"
      },
      "source": [
        "The aggregate P2P statistics combined with improvements in Card and Device metrics are significant given the limited scope of the previously flagged fraud which focused on chargebacks.  These results strongly imply that there are more sophisticated networks of fraudulent money flows behind the chargebacks rather than the chargebacks being isolated occurrences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Cr7Aa672L1fO"
      },
      "source": [
        "## Part 3: Recommending Suspicious Accounts With Centrality & Node Similarity\n",
        "\n",
        "In parts 1 & 2 we explored the graph and identified high risk fraud communities. At this stage, we may want to expand beyond our business logic to automatically identify other users that are suspiciously similar to the fraud risks already identified. Neo4j and GDS makes it simple to triage and recommend such suspect users for further investigation in a matter of seconds. We can leverage both centrality and similarity algorithms for this.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JZyfJ0OLL1fO"
      },
      "source": [
        "### Using Weighted Degree Centrality to Recommend Potential High Risk Accounts\n",
        "\n",
        "We can quickly and easily generate a ranked list of suspicious user accounts with weighted degree centrality. Specifically, we can calculate the degree centrality of users in respect to their identifiers (Devices, Cards, and IPs) weighted by the fraudRiskRatios we made in part 2. In this case, a simple Cypher query suffices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JHCRx4BVL1fO"
      },
      "outputs": [],
      "source": [
        "gds.run_cypher('''\n",
        "    MATCH(f:FraudRiskUser)-[:HAS_CC|HAS_IP|USED]->(n)\n",
        "    WITH DISTINCT n\n",
        "    MATCH(u:User)-[:HAS_CC|HAS_IP|USED]->(n) WHERE NOT u:FraudRiskUser\n",
        "    WITH left(u.guid,8) as uid,\n",
        "        sum(n.fraudRiskRatio) AS totalIdFraudRisk,\n",
        "        count(n) AS numberFraudRiskIds\n",
        "    WITH uid, totalIdFraudRisk,\n",
        "        numberFraudRiskIds,\n",
        "        totalIdFraudRisk/toFloat(numberFraudRiskIds) AS averageFraudIdRisk\n",
        "    WHERE averageFraudIdRisk >= 0.25\n",
        "    RETURN uid, totalIdFraudRisk, numberFraudRiskIds, averageFraudIdRisk\n",
        "    ORDER BY totalIdFraudRisk DESC LIMIT 10\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ZCL1e6-RL1fP"
      },
      "source": [
        "Users in the above result list are sorted by how much identifying information they share with previously labeled fraud risks, the ones with the most being at the top. Technically speaking, these users are ranked by their total Id fraud risk, which is equal to the sum of the fraudRiskRatios from the Identifiers they are connected to. In the query we also implement a limit on the average fraud risk to avoid users that just have a lot of high-degree identifiers (likely proxy ip addresses shared by only a small fraction of fraud risk users). This sort of filtering can be tweaked by use case to get the right balance between total risk vs average risk.\n",
        "\n",
        "In a real-world fraud detection use case, these results can be triaged by analysts to label more fraud accounts and grow labeled fraud communities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "5tOA3yT2L1fP"
      },
      "source": [
        "### Using Node Similarity to Expand on Fraud Communities\n",
        "\n",
        "Simple calculations like weighted degree centrality work well for identifying suspicious users over the whole graph, but what if we are interested in how users are related to a specific fraud risk community or set of communities? Perhaps we hypothesize that communities of fraud risk users are actually bigger than currently represented but we don't have exact business rules to apply. We can leverage similarity algorithms to help us score and recommend users for this.\n",
        "\n",
        "GDS offers multiple algorithms for similarity. In this analysis we will focus on the aptly named  [Node Similarity](https://neo4j.com/docs/graph-data-science/current/algorithms/node-similarity/) algorithm. Node similarity parallelizes well and is explainable. It identifies pairs of similar nodes based on a straightforward Jaccard similarity calculation. So while other ML-based similarity approaches like FastRP + KNN covered [in this post](https://neo4j.com/developer-blog/exploring-practical-recommendation-systems-in-neo4j/) scale well for running globally on very large graphs, Node Similarity is a good choice where explainability is important and you can narrow down the universe of comparisons to a subset of your data. Examples of narrowing down include focusing on just single communities, newly added users, or users within a specific proximity to suspect accounts. In this analysis we will take the third approach, filtering to just those Cards, Devices, and IP addresses that connect to at least one fraud risk account from Part 2.\n",
        "\n",
        "\n",
        "Below we apply three queries to calculate node similarity. The first query enables the identifier filtering via setting a new label on the Card, Device, and IP address nodes that connect to fraud risk accounts. The first query also weights relationships by the inverse of degree centrality, essentially downplaying the importance of identifiers proportional to the number of other users they connect to. This is important as some identifiers, particularly IP addresses, can connect to hundreds or thousands of users, in which case the identifier may be very generic (like a proxy IP address) and not as relevant to true user identity. The second and third query project the graph and write relationships back to the database with a score to represent similarity strength between user node pairs. You will notice that we use a similarity cutoff of 0.01 in the third query, which is intended to rule out weak associations and keep the similarities relevant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "EZnrhYzYL1fP"
      },
      "outputs": [],
      "source": [
        "# label identifiers and users that are close to fraud risk users and assign inverse degree weight\n",
        "gds.run_cypher('''\n",
        "    MATCH(f:FraudRiskUser)-[:HAS_CC|HAS_IP|USED]->(n)\n",
        "    WITH DISTINCT n\n",
        "    MATCH(n)<-[r:HAS_CC|HAS_IP|USED]-(u)\n",
        "    SET n:FraudSharedId\n",
        "    SET r.inverseDegreeWeight = 1.0/(n.degree-1.0)\n",
        "    RETURN count(DISTINCT n)\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4_pOO9f5L1fP"
      },
      "outputs": [],
      "source": [
        "# This cell takes a minute\n",
        "g, _ = gds.graph.project('similarity-projection', ['User', 'FraudSharedId'], ['HAS_CC', 'USED', 'HAS_IP'],\n",
        "                         relationshipProperties=['inverseDegreeWeight'])\n",
        "\n",
        "\n",
        "\n",
        "df = gds.nodeSimilarity.write(g, writeRelationshipType='SIMILAR_IDS', writeProperty='score',\n",
        "                              similarityCutoff=0.01, relationshipWeightProperty='inverseDegreeWeight', concurrency=4)\n",
        "g.drop()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "P0ApI5WZL1fP"
      },
      "source": [
        "From there, we can run a Cypher query to rank users by how similar they are to known fraud risk communities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9BOw5ND4L1fP"
      },
      "outputs": [],
      "source": [
        "#get nodes similar to the high risk ones\n",
        "gds.run_cypher('''\n",
        "    MATCH (f:FraudRiskUser)\n",
        "    WITH f.wccId AS componentId, count(*) AS numberOfUsers, collect(f) AS users\n",
        "    UNWIND users AS f\n",
        "    MATCH (f)-[s:SIMILAR_IDS]->(u:User) WHERE NOT u:FraudRiskUser AND numberOfUsers > 2\n",
        "    RETURN u.guid AS userId, sum(s.score) AS totalScore, collect(DISTINCT componentId) AS closeToCommunityIds \n",
        "    ORDER BY totalScore DESC LIMIT 5\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JiTFzjqNL1fP"
      },
      "source": [
        "***\n",
        "\n",
        "<span style=\"color:green\">  Letâ€™s take a look at the first user in the list, user `0b3f278ff6b348fb1a599479d9321cd9`.</span> \n",
        "<br>This user account seems interesting in the sense that they connect to two different communities.</span>\n",
        "\n",
        "```cypher\n",
        "MATCH (u:User {guid: \"0b3f278ff6b348fb1a599479d9321cd9\"})-[:SIMILAR_IDS]-(u2:FraudRiskUser)\n",
        "WITH u as targetUser, collect(distinct u2.wccId) as communities \n",
        "UNWIND communities as c \n",
        "MATCH (u2)-[:SHARED_IDS|P2P_WITH_SHARED_CARD]-(u3:User {wccId:c})\n",
        "RETURN *\n",
        "```\n",
        "You can see how this user connects to the two fraud risk communities and how the similarity relationships were based on shared IP addresses. This user seems to act as a sort of bridge between the two communities, suggesting not only that the user is likely part of the fraud communities but also that the two communities may actually reflect one-in-the same.\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "NMAQ_DGXL1fQ"
      },
      "source": [
        "\n",
        "Overall, centrality and similarity metrics like these are fast and easy to implement with Neo4j and GDS. They can help advance your Data Science approach by introducing automated and semi-supervised processes to assist in targeted triage and identification of suspicious user accounts based on previously labeled data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "w5jKrjFqL1fQ"
      },
      "source": [
        "## Part 4: Predicting Fraud Risk Accounts with Machine Learning\n",
        "\n",
        "In real-world scenarios we often don't know which user accounts are fraudulent ahead of time. There will be cases, like with this dataset, where some accounts get flagged due to business rules, for example chargeback history, or via user reporting mechanisms. However, as we saw in parts 1 & 2 above, those flags don't tell the whole story. The community detection and recommendation approaches we previously covered can go a very long way in helping us understand this story and label additional fraud risk users and patterns. That said, there are multiple reasons why we may want to add supervised Machine Learning to predict the additional fraud risks:\n",
        "\n",
        " - __Proactive Detection:__ We can train a model to identify fraudulent actors ahead of time (such as before additional chargebacks or system flags) and better identify new communities that aren't connected to older known fraud accounts.\n",
        " - __Measurable Performance:__ Supervised learning models produce clear performance metrics that enable us to evaluate and adjust as needed\n",
        " - __Automation:__ supervised Machine Learning automates the prediction of fraud risk accounts.\n",
        "\n",
        "In the below sections we will walk through how to engineer graph features for ML, export those features to python, then train and evaluate an ML model for fraud classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-tQAO2qL1fQ"
      },
      "source": [
        "### ML Pipeline for Node Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwEuOPmQL1fQ"
      },
      "outputs": [],
      "source": [
        "pipe, _ = gds.beta.pipeline.nodeClassification.create(\"gds_demo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "FoxqWLaCL1fQ"
      },
      "outputs": [],
      "source": [
        "# Add target labels\n",
        "gds.run_cypher('''\n",
        "    MATCH (u:User)\n",
        "    SET u.fraudLabel = u.fraudRisk - u.fraudMoneyTransfer\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "GTWdH640L1fQ"
      },
      "source": [
        "### Feature Engineering\n",
        "If we want a machine learning model to successfully classify fraud risk user accounts, we need to supply features that will be informative for the task. The below commands engineer graph features using GDS.  This includes features from [WCC](https://neo4j.com/docs/graph-data-science/current/algorithms/wcc/) community sizes, [pageRank](https://neo4j.com/docs/graph-data-science/current/algorithms/page-rank/), and [degree centrality](https://neo4j.com/docs/graph-data-science/current/algorithms/degree-centrality/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nlMGLU-GL1fQ"
      },
      "source": [
        "#### Community Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Z2pa433RL1fQ"
      },
      "outputs": [],
      "source": [
        "# Capture features for community size from our WCC community detection in Part 2, and if the user is part of a community\n",
        "gds.run_cypher('''\n",
        "    MATCH (u:User)\n",
        "    WITH u.wccId AS componentId, count(*) AS communitySize, collect(u) AS users\n",
        "    WITH communitySize, toInteger(communitySize > 1) AS partOfCommunity, users\n",
        "    UNWIND users as u\n",
        "    SET u.communitySize = communitySize\n",
        "    SET u.partOfCommunity = partOfCommunity;\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b_2UPQqL1fR"
      },
      "source": [
        "#### ID Centrality Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JY4469DL1fR"
      },
      "outputs": [],
      "source": [
        "g, _ = gds.graph.project(\"p2p-sharedid-features\", \n",
        "    {\n",
        "        \"User\": {\"label\": \"User\", \"properties\":[\"communitySize\", \"partOfCommunity\", \"fraudLabel\"]},\n",
        "        \"Card\": {\"label\": \"Card\"},\n",
        "        \"Device\": {\"label\": \"Device\"},\n",
        "        \"IP\": {\"label\": \"IP\"}\n",
        "    },\n",
        "    {\n",
        "        \"HAS_IP\": {\"type\": \"HAS_IP\", \"orientation\": \"NATURAL\"},\n",
        "        \"HAS_CC\": {\"type\": \"HAS_CC\", \"orientation\": \"NATURAL\"},\n",
        "        \"USED\": {\"type\": \"USED\", \"orientation\": \"NATURAL\"},\n",
        "        \"P2P\": {\"type\": \"P2P\", \"orientation\": \"NATURAL\", \"aggregation\": \"SUM\", \"properties\": [\"totalAmount\"]},\n",
        "        \"P2P_REVERSE\": {\"type\": \"P2P\", \"orientation\": \"REVERSE\", \"aggregation\": \"SUM\", \"properties\": [\"totalAmount\"]},\n",
        "        \"SHARED_IDS\": {\"type\": \"SHARED_IDS\", \"orientation\": \"UNDIRECTED\"},\n",
        "        \"P2P_WITH_SHARED_CARD\": {\"type\": \"P2P_WITH_SHARED_CARD\", \"orientation\": \"NATURAL\"}\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNYPBy9vL1fR"
      },
      "outputs": [],
      "source": [
        "# capture how many cards, devices, or IPs used by each user with degree centrality\n",
        "gds.degree.mutate(g, nodeLabels=['User', 'Card'], relationshipTypes=['HAS_CC'], mutateProperty='cardDegree')\n",
        "gds.degree.mutate(g, nodeLabels=['User', 'Device'], relationshipTypes=['USED'], mutateProperty='deviceDegree')\n",
        "gds.degree.mutate(g, nodeLabels=['User', 'IP'], relationshipTypes=['HAS_IP'], mutateProperty='ipDegree');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ONQdAkgL1fR"
      },
      "source": [
        "#### P2P With Cards and Id Sharing Centrality Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBiRWU1CL1fR"
      },
      "outputs": [],
      "source": [
        "gds.degree.mutate(g, nodeLabels=[\"User\"], relationshipTypes=[\"SHARED_IDS\"], mutateProperty=\"sharedIdsDegree\")\n",
        "\n",
        "gds.pageRank.mutate(g, nodeLabels=[\"User\"], relationshipTypes=[\"P2P_WITH_SHARED_CARD\"], \n",
        "                    maxIterations=1000, mutateProperty=\"p2pSharedCardPageRank\")\n",
        "\n",
        "gds.pageRank.mutate(g, nodeLabels=[\"User\"], relationshipTypes=[\"P2P\"], maxIterations=1000,\n",
        "                     mutateProperty=\"p2pSentPageRank\")\n",
        "\n",
        "gds.pageRank.mutate(g, nodeLabels=[\"User\"], relationshipTypes=[\"P2P_REVERSE\"], maxIterations=1000,\n",
        "                     relationshipWeightProperty='totalAmount', mutateProperty=\"p2pReceivedWeightedPageRank\")\n",
        "\n",
        "gds.degree.mutate(g, nodeLabels=[\"User\"], relationshipTypes=[\"P2P_REVERSE\"], \n",
        "                  relationshipWeightProperty='totalAmount', mutateProperty=\"p2pReceivedWeightedDegree\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "39vcaO3GL1fR"
      },
      "source": [
        "### Feature Selection\n",
        "Select features from the list of features we generated in the previous step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFTSxhQ6L1fR"
      },
      "outputs": [],
      "source": [
        "pipe.selectFeatures([\"communitySize\", \"partOfCommunity\", \"cardDegree\", \"deviceDegree\", \"ipDegree\",\n",
        "                    \"sharedIdsDegree\", \"p2pSharedCardPageRank\", \"p2pSentPageRank\",\n",
        "                     \"p2pReceivedWeightedPageRank\", \"p2pReceivedWeightedDegree\"\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6EPx_AtL1fR"
      },
      "outputs": [],
      "source": [
        "pipe.feature_properties()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jd_zTd5EL1fS"
      },
      "outputs": [],
      "source": [
        "pipe.addLogisticRegression(maxEpochs=500, penalty=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dWdct8cL1fS"
      },
      "outputs": [],
      "source": [
        "# Train the pipeline targeting node property \"my-class\" as label and \"ACCURACY\" as only metric\n",
        "trained_pipe_model, res = pipe.train(g, targetNodeLabels=['User'], modelName=\"my-model\", targetProperty=\"fraudLabel\", metrics=[\"ACCURACY\", \"RECALL(CLASS=*)\", \"F1_WEIGHTED\"], concurrency=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFnYFsI8L1fS"
      },
      "outputs": [],
      "source": [
        "trained_pipe_model.metrics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zT0j91HVL1fS"
      },
      "source": [
        "#### Write computed features to the database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEWwFUfOL1fS"
      },
      "outputs": [],
      "source": [
        "gds.graph.writeNodeProperties(g, [\"cardDegree\", \"deviceDegree\", \"ipDegree\",\n",
        "                    \"sharedIdsDegree\", \"p2pSharedCardPageRank\", \"p2pSentPageRank\",\n",
        "                     \"p2pReceivedWeightedPageRank\", \"p2pReceivedWeightedDegree\"\n",
        "                    ], ['User'])\n",
        "g.drop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjLKH5sfL1fS"
      },
      "source": [
        "### Machine Learning Training & Evaluation using scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id5d95abL1fS"
      },
      "source": [
        "#### Add target label weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4wEX5zUL1fS"
      },
      "outputs": [],
      "source": [
        "# for use with ML frameworks that take indo account weights on target label when training the model \n",
        "gds.run_cypher('''\n",
        "MATCH (u:User) WITH count(u) as numSamples\n",
        "MATCH (u:User) WHERE u.fraudLabel > 0  WITH numSamples, count(u) as negativeSamples\n",
        "MATCH (u:User)  WITH u, numSamples, negativeSamples,\n",
        "\n",
        "CASE u.fraudLabel\n",
        "WHEN 1 THEN toFloat(numSamples)/(2 * negativeSamples)\n",
        "ELSE toFloat(numSamples)/(2 * (numSamples - negativeSamples))\n",
        "END as weight\n",
        "\n",
        "SET u.fraudLabelWeight = weight\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIb0FaGgL1fT"
      },
      "source": [
        "#### Get and Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xBRlIVIfL1fT"
      },
      "outputs": [],
      "source": [
        "df = gds.run_cypher('''\n",
        "    MATCH(u:User)\n",
        "    RETURN u.guid AS guid,\n",
        "        u.wccId AS wccId,\n",
        "        u.fraudLabel AS fraudLabel,\n",
        "        u.fraudLabelWeight AS fraudLabelWeight,\n",
        "        u.sharedIdsDegree AS sharedIdsDegree,\n",
        "        u.p2pSharedCardPageRank AS p2pSharedCardPageRank,\n",
        "        u.p2pSentPageRank AS p2pSentPageRank,\n",
        "        u.p2pReceivedWeightedPageRank AS p2pReceivedWeightedPageRank,\n",
        "        u.p2pReceivedWeightedDegree AS p2pReceivedWeightedDegree,\n",
        "        u.ipDegree AS ipDegree,\n",
        "        u.cardDegree AS cardDegree,\n",
        "        u.deviceDegree AS deviceDegree,\n",
        "        u.communitySize AS communitySize,\n",
        "        u.partOfCommunity AS partOfCommunity\n",
        "''')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5tfmolakL1fT"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['fraudLabel', 'fraudLabelWeight', 'wccId', 'guid'])\n",
        "y = df.fraudLabel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2waj2llWL1fT"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cc8xODQaL1fT"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8rDsrdlKL1fT"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "bTjCVJQ6L1fT"
      },
      "source": [
        "#### Model Training and Evaluation\n",
        "\n",
        "For purposes of this demo we are going to use a random forest classifier. Other classifiers including logistic regression, SVM, Neural Nets and Boosting variants could work as well. Going into the exact pros and cons of these models is out of scope here. Overall, exploring classification with Random Forests is a safe bet since they are relatively robust to feature scaling and collinearity issues and require minimal tuning to get working well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ave39_O6L1fT"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=500, random_state=0, max_depth=5, bootstrap=True, class_weight='balanced')\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pUeJfgE8L1fU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "print('Accuracy of random forest classifier on test set: {:.2f}'.format(clf.score(X_test, y_test)))\n",
        "print('\\nConfusion Matrix: ')\n",
        "disp = ConfusionMatrixDisplay.from_predictions(y_test, clf.predict(X_test), display_labels=clf.classes_,\n",
        "                                               cmap='Greys', colorbar=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "t6phDTc_L1fU"
      },
      "source": [
        "Below is a ranked list of the most influential features. Among the most important are the community sizes and the shared ids degree and p2p shared card pageRank."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "oWs-KDAcL1fU"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "result = permutation_importance(clf, X_train, y_train, random_state=0)\n",
        "pd.DataFrame(abs(result['importances_mean']),index=X_train.columns).sort_values(0, ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "0tbmuI63L1fU"
      },
      "source": [
        "### Investigating Unlabeled High-Probability Fraud Risk Predictions\n",
        "The labeling from part 2 wasn't perfect. Now that we have trained a machine learning model, investigating user accounts that were predicted as high probability fraud risks despite not being labeled as such by us (ostensible false positives), will bring further insights.\n",
        "\n",
        "The below commands will isolate some cases from the test set so we can visualize in Neo4j Browser or [Neo4j Bloom](https://neo4j.com/product/bloom/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lokZqcvLL1fU"
      },
      "outputs": [],
      "source": [
        "# Retrieve High Probability predictions for non-fraud risk labeled data in the testset\n",
        "y_prob = clf.predict_proba(X_test)\n",
        "y_test_df = y_test.to_frame(name='cls')\n",
        "y_test_df['predictedProbability']=y_prob[:, 1]\n",
        "test_prob_df = y_test_df[(y_test_df.predictedProbability > 0.88) & (y_test_df.cls == 0)] \\\n",
        "    .join(df[['guid','wccId', 'communitySize']])\n",
        "test_prob_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ODTmzEp7L1fU"
      },
      "outputs": [],
      "source": [
        "#Write back to database for investigation in Bloom\n",
        "for index, row in test_prob_df.iterrows():\n",
        "    gds.run_cypher('''\n",
        "        MATCH(u:User) WHERE u.guid = $guid\n",
        "        SET u.predictedProbability = $predictedProbability\n",
        "    ''', params = row.to_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "o92g2w15L1fU"
      },
      "source": [
        "*** \n",
        "<span style=\"color:green\"> You can look at the predicted fraudulent users and their community using an example like the below. </span>\n",
        "<br>Hint: Set the User node caption to be `predictedProbability` to more easily identify the suspect! \n",
        "\n",
        "```cypher \n",
        "MATCH (u:User) WHERE u.guid=\"c4d3c05ebf06a6b7b2f10833a51a0b70\" \n",
        "WITH u.wccId as commId\n",
        "MATCH p=(c:User)-[:P2P|HAS_IP|HAS_CC|USED*1..2]-(d:User) \n",
        "WHERE c.wccId=commId and d.wccId=commId and id(c)<>id(d)\n",
        "RETURN p;\n",
        "``` \n",
        "*** \n",
        "Perhaps unsurprisingly, these examples exhibit P2P payments with shared card behavior. They also have a relatively large number of credit cards (the median degree centrality on cards is 3). This could potentially be a sign of fraud, though it is hard to know on an anonymized dataset like this. This is where subject matter expert review and iteration comes in. If this behavior turns out to be a clear indicator of fraud, it means we are predicting fraud more proactively before chargebacks take place which is the ideal. In this case, if we re-label these users appropriately and re-train our ML model as more data comes in, we will further improve predictive performance. If, on the other hand, it turns out that some of this behavior is benign, we can adjust the feature engineer and model so the ML learns to rule out such cases which will likewise improve predictive performance and increase our understanding of fraud patterns. Either way, it is a win.\n",
        "\n",
        "### Additional Visualization with Bloom\n",
        "<br>You can also explore more custom styling and user workflows with the Neo4j visualization tool [Bloom](https://neo4j.com/docs/bloom-user-guide/current/) - try the query above as a \"Saved Cypher\" Search phrase, with guid as a parameter! \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "G3Dir37dL1fU"
      },
      "source": [
        "-------------\n",
        "------ \n",
        "## Clean Up\n",
        "This section will help clean all the additional graph elements and properties created in the above workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwVHbZUIL1fU"
      },
      "outputs": [],
      "source": [
        "# drop all pipelines \n",
        "p_names = gds.beta.pipeline.list().pipelineName.tolist()\n",
        "for p_name in p_names: \n",
        "    p = gds.pipeline.get(p_name)\n",
        "    gds.beta.pipeline.drop(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEMCQHz_L1fV"
      },
      "outputs": [],
      "source": [
        "# drop all inmemory graphs\n",
        "gdf = gds.graph.list()\n",
        "# make sure only trying to drop graphs in current db\n",
        "g_names = gdf[gdf['database']==DATABASE].graphName.tolist()\n",
        "for g_name in g_names:\n",
        "    g = gds.graph.get(g_name)\n",
        "    gds.graph.drop(g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVfVJNu1L1fV"
      },
      "outputs": [],
      "source": [
        "# drop all models\n",
        "models = gds.run_cypher(\"CALL gds.beta.model.list()\")\n",
        "for m in models['modelInfo']:\n",
        "    gds.run_cypher('''CALL gds.beta.model.drop(\"{}\")'''.format(m['modelName']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6ZbF6ctBL1fV"
      },
      "outputs": [],
      "source": [
        "# delete created relationships\n",
        "gds.run_cypher('MATCH (:User)-[r:SHARED_IDS]->() DELETE r')\n",
        "gds.run_cypher('MATCH (:User)-[r:P2P_WITH_SHARED_CARD]->() DELETE r')\n",
        "gds.run_cypher('MATCH (:User)-[r:SIMILAR_IDS]->() DELETE r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IOKZ0OhRL1fV"
      },
      "outputs": [],
      "source": [
        "# remove created node Labels\n",
        "gds.run_cypher('MATCH (u:FlaggedUser) REMOVE u:FlaggedUser')\n",
        "gds.run_cypher('MATCH (u:FraudRiskUser) REMOVE u:FraudRiskUser')\n",
        "gds.run_cypher('MATCH (u:FraudSharedId) REMOVE u:FraudSharedId')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aHoZow2tL1fV"
      },
      "outputs": [],
      "source": [
        "# remove created node properties\n",
        "gds.run_cypher('''\n",
        "    MATCH (n)\n",
        "    REMOVE n.wccId,\n",
        "        n.sharedIdsDegree,\n",
        "        n.predictedProbability,\n",
        "        n.partOfCommunity,\n",
        "        n.p2pSharedCardPageRank,\n",
        "        n.p2pSharedCardDegree,\n",
        "        n.p2pSentWeightedPageRank,\n",
        "        n.p2pSentWeightedDegree,\n",
        "        n.p2pSentPageRank,\n",
        "        n.p2pSentDegree,\n",
        "        n.p2pReversedSharedCardPageRank,\n",
        "        n.p2pReversedSharedCardDegree,\n",
        "        n.p2pReceivedWeightedPageRank,\n",
        "        n.p2pReceivedWeightedDegree,\n",
        "        n.p2pReceivedPageRank,\n",
        "        n.p2pReceivedDegree,\n",
        "        n.louvainCommunityId,\n",
        "        n.ipDegree,\n",
        "        n.fraudLabel,\n",
        "        n.fraudLabelWeight,\n",
        "        n.fraudRiskRatio,\n",
        "        n.fraudRiskDegree,\n",
        "        n.fraudRisk,\n",
        "        n.flaggedRatio,\n",
        "        n.flaggedDegree,\n",
        "        n.deviceDegree,\n",
        "        n.degree,\n",
        "        n.communitySize,\n",
        "        n.cardDegree\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "e5bkGYYpL1fV"
      },
      "outputs": [],
      "source": [
        "# remove created relationship properties\n",
        "gds.run_cypher('MATCH ()-[r]->() REMOVE r.inverseDegreeWeight')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}